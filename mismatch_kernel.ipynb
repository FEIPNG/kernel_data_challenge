{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "def generate_kmers(sequence, k):\n",
    "    \"\"\"Generate all k-mers of a given sequence.\"\"\"\n",
    "    return [sequence[i:i+k] for i in range(len(sequence) - k + 1)]\n",
    "\n",
    "def hamming_distance(s1, s2):\n",
    "    \"\"\"Compute the Hamming distance between two strings.\"\"\"\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "def generate_mismatch_kmers(kmer, m, alphabet=\"ACGT\"):\n",
    "    \"\"\"\n",
    "    Generate all possible k-mers within Hamming distance `m` of the given `kmer`.\n",
    "    \n",
    "    Args:\n",
    "        kmer: Original k-mer string.\n",
    "        m: Maximum number of allowed mismatches.\n",
    "        alphabet: Allowed nucleotide characters.\n",
    "\n",
    "    Returns:\n",
    "        Set of k-mers within `m` mismatches.\n",
    "    \"\"\"\n",
    "    mismatched_kmers = set()\n",
    "    k = len(kmer)\n",
    "\n",
    "    # Generate all possible k-mers\n",
    "    for positions in product(range(k), repeat=m):  # Positions to mutate\n",
    "        for replacements in product(alphabet, repeat=m):  # Replacement letters\n",
    "            kmer_list = list(kmer)\n",
    "            for pos, new_char in zip(positions, replacements):\n",
    "                kmer_list[pos] = new_char  # Mutate positions\n",
    "            mismatched_kmers.add(\"\".join(kmer_list))\n",
    "\n",
    "    return mismatched_kmers\n",
    "\n",
    "def mismatch_kernel(X1, X2, k, m):\n",
    "    \"\"\"\n",
    "    Compute the Mismatch Kernel matrix.\n",
    "    \n",
    "    Args:\n",
    "        X1: List of sequences (training or test).\n",
    "        X2: List of sequences (training).\n",
    "        k: k-mer length.\n",
    "        m: Max number of mismatches allowed.\n",
    "\n",
    "    Returns:\n",
    "        Kernel matrix of shape (len(X1), len(X2)).\n",
    "    \"\"\"\n",
    "    kernel_matrix = np.zeros((len(X1), len(X2)))\n",
    "    \n",
    "    for i, seq1 in enumerate(X1):\n",
    "        kmer_counts_1 = {}\n",
    "        for kmer in generate_kmers(seq1, k):\n",
    "            for mismatch_kmer in generate_mismatch_kmers(kmer, m):\n",
    "                kmer_counts_1[mismatch_kmer] = kmer_counts_1.get(mismatch_kmer, 0) + 1\n",
    "        \n",
    "        for j, seq2 in enumerate(X2):\n",
    "            kmer_counts_2 = {}\n",
    "            for kmer in generate_kmers(seq2, k):\n",
    "                for mismatch_kmer in generate_mismatch_kmers(kmer, m):\n",
    "                    kmer_counts_2[mismatch_kmer] = kmer_counts_2.get(mismatch_kmer, 0) + 1\n",
    "\n",
    "            # Compute dot product between mismatch k-mer counts\n",
    "            kernel_matrix[i, j] = sum(kmer_counts_1[kmer] * kmer_counts_2.get(kmer, 0) for kmer in kmer_counts_1)\n",
    "    \n",
    "    return kernel_matrix\n",
    "\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))\n",
    "\n",
    "def logistic_loss(beta, K, y, C):\n",
    "    \"\"\"Logistic loss function for kernelized logistic regression.\"\"\"\n",
    "    linear_term = K @ beta  # K * beta\n",
    "    loss = np.mean(np.log(1 + np.exp(-y * linear_term))) + (C / 2) * np.dot(beta, beta)\n",
    "    return loss\n",
    "\n",
    "def train_logistic_regression(K_train, y_train, C=1.0):\n",
    "    \"\"\"Train logistic regression with kernel trick using optimization.\"\"\"\n",
    "    beta_init = np.zeros(K_train.shape[0])\n",
    "\n",
    "    res = minimize(fun=logistic_loss, x0=beta_init, args=(K_train, y_train, C), method='L-BFGS-B')\n",
    "\n",
    "    return res.x  # Optimal beta\n",
    "\n",
    "def predict_logistic_regression(K_test, beta):\n",
    "    \"\"\"Make predictions using kernelized logistic regression.\"\"\"\n",
    "    probs = sigmoid(K_test @ beta)\n",
    "    return np.where(probs >= 0.5, 1, -1)\n",
    "\n",
    "def train_and_predict_mismatch_logistic(X_train_path, Y_train_path, X_test_path, k=6, m=1, C=1.0):\n",
    "    \"\"\"Pipeline for training and predicting with Mismatch Kernel Logistic Regression.\"\"\"\n",
    "    # Load data\n",
    "    df_train = pd.read_csv(X_train_path)\n",
    "    df_labels = pd.read_csv(Y_train_path)\n",
    "    df_test = pd.read_csv(X_test_path)\n",
    "\n",
    "    X_train = df_train[\"seq\"].values\n",
    "    y_train = np.where(df_labels[\"Bound\"] == 1, 1, -1)  # Convert labels to {-1,1}\n",
    "    X_test = df_test[\"seq\"].values\n",
    "\n",
    "    # Compute kernel matrices\n",
    "    K_train = mismatch_kernel(X_train, X_train, k, m)\n",
    "    K_test = mismatch_kernel(X_test, X_train, k, m)\n",
    "\n",
    "    # Train logistic regression model\n",
    "    beta = train_logistic_regression(K_train, y_train, C)\n",
    "\n",
    "    # Make predictions\n",
    "    predictions = predict_logistic_regression(K_test, beta)\n",
    "\n",
    "    # Convert {-1,1} predictions to {0,1}\n",
    "    df_test[\"Bound\"] = (predictions + 1) // 2\n",
    "\n",
    "    return df_test\n",
    "\n",
    "# === Run the function ===\n",
    "df_predictions = train_and_predict_mismatch_logistic(\"./data/Xtr0.csv\", \"./data/Ytr0.csv\", \"./data/Xte0.csv\", k=6, m=1, C=1.0)\n",
    "\n",
    "# Save predictions\n",
    "df_predictions.to_csv(\"mismatch_predictions.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
